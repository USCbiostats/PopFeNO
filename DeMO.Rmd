---
title: 'Multiple flow FeNO in population research: R code methods demo'
output:
  html_document: default
  pdf_document: default
  word_document: default
---

The following demonstration  provides example R codes to implement six methods for cross-sectional studies with multiple flow exhaled nitric oxide (FeNO) measurements, where the goal is to relate estimated NO parameters to factors of interest (i.e., covariate(s) X) in the study population. 

## 0. Preliminaries: set up your R session

IMPORTANT! To apply out bayesian approaches, please install JAGS, if not already installed, follow instructions at: https://mcmc-jags.sourceforge.io/

Load the following required packages, installing first if not already available.
To use the R2jags package, JAGS must be pre-installed.

```{r presetup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE,tidy.opts=list(width.cutoff=60),tidy=TRUE,eval=FALSE)
rm(list=ls())
```

```{r setup, message=FALSE,warning=FALSE}
# set working directory
setwd("K:/paper/newpackage/PopFeNO")
# load required packages
require(MASS)
require(lme4)
require(nlme)
require(reshape2)
require(R2jags)
require(knitr)

```

<br>


## 1. FeNO data preparation

We use the long format FeNO data for all methods. The long format refers to the data structure with rows for maneuvers and columns for variables, e.g. measured FeNO, flow rates, and environmental factor/s. Our example was based on single factor X, while the models were also available to deal with multiple linear regression models or other more complex models with some modification. We also impute the measured FeNO with natural logarithmic transformation to adapt its increased randomness (ref). Each participant may took different numbers of maneuver at multiple exhale flow rates. There is an addition column, "target flow rates" to help categorizing the flow rates into low, median and high levels for Högman & Merilänen Algorithm (HMA) method. The flow rates were not necessary been exactly the same within categories, since it was not realistic during test. The popular "target flow rates" were 30, 50, 100 and 300ml/s where HMA methods only used 30, 50, and 300 ml/s. Users may input their own collected data or generate it via our simulation function (**DataGeneratorCS**) based on the two compartment (2CM) FeNO function. 


$$FeNO = C_{aw} + (C_A-C_{aw}) \times e^{-\frac{D_{aw}}{flow}}$$

Along with the available real world FeNO data, we also provide data simulation functions to mimic the actual data based on the two compartment model. Here we modified the 2CM model to log transform both sides of it and used the logged CawNO and DawNO form. We wrote the distribution function as follows:


$$log(FeNO) \sim \mathcal{N} \left(exp(logC_{aw}) + (C_A-exp(logC_{aw}) )\times e^{-\frac{exp(logD_{aw})}{flow}},\sigma^2 \right)$$
Several parameters were required for simulation FeNO data. We set some of them like the population mean, variances and correlations of NO parameters as default with the values measures from part of CHS (ref) data. Users can update them with their own numbers.

### Parameters required for simulate FeNO data are:

1: Number of Participants: **Ndat**

2: The variance covariance matrix of NO parameters [Ca, log(CawNO), log(DawNO)]: **NOcov**, a 3 by 3 matrix, which should be positive definite. 

3: Flow rates for each maneuver: **flow**, a vector, length equals to total number of observations (maneuver), ordered by the participant id

4: Standard deviation of measurement error: **SDerror**, we defined the measurement error follows normal distribution with mean 0 and standard deviation

5: Environmental factor: **X**, a vector, length equals to total number of participants, ordered by the participant id. 

6: Coefficient: **beta1**, a length 3 vector, the effect sizes for each of the three NO parameters' response to environmental factor **X**

<br>


### Data simulation Process

1: set a random seed for your work.
```{r seed}
set.seed(2020)
```

2: Generate NO parameters for each participant

**Ndat**: 500 participants

**Nocov**: The covariance matrix of NO parameters were constructed with: 
```{r,echo=FALSE}
NOcovTable<-data.frame("SD Ca" = 0.45, "SD logCaw" = 0.65,"SD logDaw"=0.55,"Cor(Ca, logCaw)" = 0.66, "Cor(Ca, logDaw)" = -0.38,"Cov(logCaw, logDaw)" = -0.35)
knitr::kable(NOcovTable,col.names = c("SD Ca","SD logCaw","SD logDaw", "Cor(Ca, logCaw)", "Cor(Ca, logDaw)", "Cov(logCaw, logDaw)"))

```


**Flow rates**: With a dropping/missing rate of 0.1 and random deviation taken the form of standard normal distribution, each participant was assigned a target flow rates of 30, 50, 100, and 300 ml/s

**SDerror**: The standard deviation of measurement error equals to 0.1

**X**: identically independently distributed vector, generated by rnorm(Ndat,0,1)

**beta1**: The covariate coefficients equal to 0.1 for each NO parameter

In this example, we generated data for 500 participants with a single vector X (Environmental factor, length=500), which had  a standard normal distribution (though in practice, X can have any distribution) and multiple flow FeNO (8 maneuvers per participant, two each at the target flow rates of 30, 50, 100, and 300 ml/s). Participant-level NO parameters (CANO, CawNO and DawNO) are generated with linear functions of X, except that rather than CawNO or DawNO, we generate logCawNO and logDawNO to better replicate the approximately log normal distribution observed in practice and to avoid negative estimates in later modeling. For example, participant-level $CANO_i = 1.5 + 0.1 \times X_i + \epsilon_i$ where the standard deviation of the random normal error $\epsilon_i$ is a normal distributed: $\epsilon \sim \mathcal{N}(0,0.45)$. While we could generate each of the three NO parameters separately, we instead generate the three NO parameters from a multivariate normal distribution to introduce correlation between NO parameters. Given the NO parameters, FeNO at each maneuvers can then be generated according to the two compartment model mentioned above. 

3: Allow unbalance and randomness for flow rates

To mimic the real world data, we allows for unbalance and randomness of flow rates in our simulated data by a given probability of dropping/missing of maneuvers and random noises as the deviates from the target flow during test. The final FeNO data could have different numbers of maneuvers for each participant and the flow rates could be slightly different from the target flow rates. 

```{r datasim,eval=FALSE}
# Simulate a multiple flow FeNO dataset in a study population
# Users can use their own flow data, with labels of target flows as "low", "medium" and "high"
# The input flow data should be in matrix form, each row represent a participant.
# Labels of target flow can be attached at last or been manually added after the data generated.
# The number of flows for each participant are not necessary equal.

source("DataG.R")       # code to generate multiple flow FeNO datasets
flow=c(rep(30,2),rep(50,2),rep(100,2),rep(300,2))
truebeta=c(0.1,0.1,0.1)
out <- DataGeneratorCS(Ndat=100,           # number of study participants
                      alpha=c(1.5,3.5,2.5),# vector of NO parameter population means, 
                                           # when X=0, in this order: CA, logCaw, logDaw
                      # function to generate participant-level covariate X 
                      # as function of number of study participants
                      Xfn=function(n){rnorm(n,0,1)}, 
                      # vector of regression coefficients relating X to NO parameters, 
                      # in this order: CA, logCaw, logDaw
                      beta=truebeta, 
                      # vector of flow rates in multiple flow FeNO protocol
                      Flow=c(rep(30,2),rep(50,2),rep(100,2),rep(300,2)), 
                      
                      SD=0.1,              #SD of the error
                      sdalphaCa            = 0.45, # population SD of CA
                      sdalphalogCaw        = 0.65, # population SD of logCaw
                      sdalphalogDaw        = 0.55, # population SD of logDaw
                      coralphalogCawCa     = 0.66, # correlation of logCaw, CA
                      coralphalogCawlogDaw = -0.35,# correlation of logCaw, logDaw
                      coralphalogDawCa     = -0.38 # correlation of logDaw, CA
                     )
# output is two versions of the same dataset, plus dataset only including X and id
# one dataset for use in Bayesian methods via JAGS (datJAGS)
# one dataset for all other methods (dat)
dat     <- out$dat
datJAGS <- out$datJAGS
datX    <- out$datX 

out2<-DataGeneratorCS_UbN(Ndat=10,            # number of study participants
                          alpha=c(1.5,3.5,2.5),# vector of NO parameter population means, when X=0, in this order: CA, logCaw, logDaw
                          Xfn=function(n){rnorm(n,0,1)},# function to generate participant-level covariate X as function of number of study participants
                          beta=c(0.1,0.1,0.1),
                          flowTarget=c(rep(30,2),rep(50,2),rep(100,2),rep(300,2)),# vector of regression coefficients relating X to each NO parameter, in this order: CA, logCaw, logDaw
                          Flow=FlowFun(10,0.9), # Must be a Ndat*max length of flow matrix, missing values were 0s
                          SD=0.1,              #SD of the error
                          sdalphaCa            = 0.45, # population SD of CA
                          sdalphalogCaw        = 0.65, # population SD of logCaw
                          sdalphalogDaw        = 0.55, # population SD of logDaw
                          coralphalogCawCa     = 0.66, # correlation of NO parameters: logCaw, CA
                          coralphalogCawlogDaw = -0.35,# correlation of NO parameters: logCaw, logDaw
                          coralphalogDawCa     = -0.38 # correlation of NO parameters: logDaw, CA
)
dat <- out2$dat
datX<- out2$datX



DataGeneratorCS(Ndat=10,            # number of study participants
                          alpha=c(1.5,3.5,2.5),# vector of NO parameter population means, when X=0, in this order: CA, logCaw, logDaw
                          X = Xfn(Ndat),# function to generate participant-level covariate X as function of number of study participants
                          beta=c(0.1,0.1,0.1),
                          flowTarget=c(rep(30,2),rep(50,2),rep(100,2),rep(300,2)),# vector of regression coefficients relating X to each NO parameter, in this order: CA, logCaw, logDaw
                          Flow=FlowFun(10,0.9), # Must be a Ndat*max length of flow matrix, missing values were 0s
                          SD=0.1,              #SD of the error
                          sdalphaCa            = 0.45, # population SD of CA
                          sdalphalogCaw        = 0.65, # population SD of logCaw
                          sdalphalogDaw        = 0.55, # population SD of logDaw
                          coralphalogCawCa     = 0.66, # correlation of NO parameters: logCaw, CA
                          coralphalogCawlogDaw = -0.35,# correlation of NO parameters: logCaw, logDaw
                          coralphalogDawCa     = -0.38 # correlation of NO parameters: logDaw, CA
)
```

3: The resultant dataset is in the usual 'long' data format:
```{r dataview,echo=FALSE}
kable(dat[1:10,])
```

* The intercepts and slopes of the linear regression moedls: NOparam ~ X of the simulated data, used in the plotting section:

These regressions were can be used for a more "concise" comparison with the estimated results.

```{r,echo=FALSE}
estParam<-lm(out2$datNOparam~datX[,2])$coef
kable(estParam)
```

<br>

## 2. Estimate NO parameter associations with X

We are interested in discovering the impact of environmental factor to the NO parameters. Those values were usually estimated in "two-stage" approaches which use the estimated NO parameters as the dependent variables. The corresponding methods were "unified" approach, which use the NO parameters as intermediate variables. We presented 4 two-stage methods and 2 unified methods here. 

<br>

### 2.1 TS_NLS: Two-stage nonlinear least squares

**Functions**

1: NLS_StageI: Estimated NO paramteres ordered by id, exist NAs

2: NLS_StageIX: Combine NO paramters and covariate X by id

3: Fit individual grouped linear regression models for each NO parameters

```{r tsnls, warning=FALSE, message=FALSE}
source("TS_NLS.R")

# Stage I 
NLS_StageI<-TS_NLS_StageI(dat)

# create dataset including both Stage I estimates and X
NLS_StageIX <- merge(NLS_StageI,datX,by="id")

# Stage II -  edit to include any additional Stage II covariates (e.g., confounder adjustments)
TS_NLS_Ca     <-lme(Ca ~ X,     random=~1|id, data = NLS_StageIX, na.action = na.omit)
TS_NLS_logCaw <-lme(logCaw ~ X, random=~1|id, data = NLS_StageIX, na.action = na.omit)
TS_NLS_logDaw <-lme(logDaw ~ X, random=~1|id, data = NLS_StageIX, na.action = na.omit)

```

**Interpretation Example: **

1: CANO

The population mean CANO is `r round(intervals(TS_NLS_Ca,which="fixed")[[1]][1,2],2)` (95% CI: `r round(intervals(TS_NLS_Ca,which="fixed")[[1]][1,1],2)`,`r  round(intervals(TS_NLS_Ca,which="fixed")[[1]][1,3],)`). 

For 1 unit increase in covariate X, CANO increases `r  round(intervals(TS_NLS_Ca,which="fixed")[[1]][2,2],2)`, (95% CI: `r round(intervals(TS_NLS_Ca,which="fixed")[[1]][2,1],2)`, `r round(intervals(TS_NLS_Ca,which="fixed")[[1]][2,3],2)`).

2. CawNO and DawNO from their log version: 

The population mean CawNO is `r round(intervals(TS_NLS_logCaw,which="fixed")[[1]][1,2],2)` (95% CI: `r round(intervals(TS_NLS_logCaw,which="fixed")[[1]][1,1],2)`,`r  round(intervals(TS_NLS_logCaw,which="fixed")[[1]][1,3],)`). 

For 1 unit increase in covariate X, CawNO increases `r  round((exp(intervals(TS_NLS_logCaw,which="fixed")[[1]][2,2])-1)*100,2)`%, (95% CI: `r  round((exp(intervals(TS_NLS_logCaw,which="fixed")[[1]][2,1])-1)*100,2)`%, `r  round((exp(intervals(TS_NLS_logCaw,which="fixed")[[1]][2,3])-1)*100,2)`%).

The population mean DawNO is `r round(intervals(TS_NLS_logDaw,which="fixed")[[1]][1,2],2)` (95% CI: `r round(intervals(TS_NLS_logDaw,which="fixed")[[1]][1,1],2)`,`r  round(intervals(TS_NLS_logDaw,which="fixed")[[1]][1,3],)`). 

For 1 unit increase in covariate X, DawNO increases `r  round((exp(intervals(TS_NLS_logDaw,which="fixed")[[1]][2,2])-1)*100,2)`%, (95% CI: `r  round((exp(intervals(TS_NLS_logDaw,which="fixed")[[1]][2,1])-1)*100,2)`%, `r  round((exp(intervals(TS_NLS_logDaw,which="fixed")[[1]][2,3])-1)*100,2)`%).


<br>

### 2.2 TS_HMA: Two-stage Högman & Merilänen Algorithm 

HMA algorithm only uses flow rates in three categories. In our example, we labeled low, median and high for target flow rates 30,100 and 300 ml/s. 

The interpretations of results were the same as those in TS_NLS

```{r tshma, warning=FALSE, message=FALSE}
source("TS_HMA.R")

# Stage I, specify target flow rates for  HMA (low, medium, high)
HMA_StageI  <- TS_HMA_StageI(dat, flowLMH=c(30,100,300))

# create dataset including both Stage I estimates and X
HMA_StageIX <- merge(HMA_StageI,datX,by="id")

# Stage II -  edit to include any additional Stage II covariates (e.g., confounder adjustments)
TS_HMA_Ca      <-lme(Ca ~ X,     random=~1|id,data = HMA_StageIX, na.action = na.omit)
TS_HMA_logCaw  <-lme(logCaw ~ X, random=~1|id,data = HMA_StageIX, na.action = na.omit)
TS_HMA_logDaw  <-lme(logDaw ~ X, random=~1|id,data = HMA_StageIX, na.action = na.omit)

```

<br>

### 2.3 TS_NLME: Two-stage nonlinear mixed effects model

```{r tsnlme, warning=FALSE, message=FALSE, results='hide', cache=TRUE}
if(!file.exists("TSNLME_cc.Rdata")){
  set.seed(2020)
  source("TS_NLME.R")
  #Stage I
  TSNLME_StageIout <- TS_NLME_StageI(dat,tol1=0.1,tol2=0.1,outputFit=TRUE)# include X for later unified version
  save(TSNLME_StageIout,file="TSNLME_cc.Rdata")
}else{
  load("TSNLME_cc.Rdata")
}
TSNLME_StageI    <- TSNLME_StageIout$ests
TSNLME_StageIfit <- TSNLME_StageIout$fit  # save fit to speed up U_NLME

# create dataset including both Stage I estimates and X
TSNLME_StageIX <- merge(TSNLME_StageI,datX,by="id")

  # Stage II -  edit to include any additional Stage II covariates (e.g., confounder adjustments)
TS_NLME_Ca     <-lme(Ca ~ X,     random=~1|id, data = TSNLME_StageIX, na.action = na.omit)
TS_NLME_logCaw <-lme(logCaw ~ X, random=~1|id, data = TSNLME_StageIX, na.action = na.omit)
TS_NLME_logDaw <-lme(logDaw ~ X, random=~1|id, data = TSNLME_StageIX, na.action = na.omit)
```


### 2.4 UNLME: Unified nonlinear mixed effects model

**Notation**

There are two different approaches to fit the unified NLME model. The "Direct" approach fit the model with initial values via approximation; the "Update" approach utilize the fitted two-stage version and update it with added regressions between NO parameters and X. 

```{r unlme, message=FALSE, results='hide', cache=TRUE,warning=FALSE}

if(!file.exists("UNLME_cc.Rdata")){
  set.seed(2020)
  # The function is for single X. If you want to fit with multiple X, just modify the "fixed" and    start statement of the function
  source("U_NLME.R")
  # direct approach
  U_NLMEout<-U_NLME_direct(dat,datX,tol=0.1)
  # update approach
  #U_NLMEout_u<-U_NLME_update(TSNLME_StageIout,dat,datX,tol=0.1)
  # anova(U_NLMEout,U_NLMEout_u) # compare two approaches
  save(U_NLMEout,file="UNLME_cc.Rdata")
}else{
  load("UNLME_cc.Rdata")
}
  

```

### 2.5 TS_HB: Two-stage Hierarchical Bayesian method

The HB methods usually take hours to finish, so here we loaded the already fitted results. TS_HB methods was the alternative version for the U_HB to have a quicker pilot results, especially when the regression models between NO parameters and X become complex. It is also a "fair" comparison with other two stage methods.


```{r tshb, results='hide', cache=TRUE,message=FALSE}


# Stage I
#if(!file.exists("TSHB_cc.Rdata")){
    set.seed(2020)
    source("TS_HB.R")
  
   
    TSHB_S1<-TSHB_iter_UB(beta0_prior=c(2,4,3),
             rhat=1.1,addon.iter=60,Max_update=10,
             n.final=60,N.iterT=550,N.burnin=500,N.thinM=1,N.chain=3,
             flow=flow,dat=dat,
             tracing=c("beta0_Ca","beta0_logCaw","beta0_logDaw",
                       "sdCa","sdlogCaw","sdlogDaw",
                       "corlogCawCa","corlogCawlogDaw","corlogDawCa",
                       "sigma_c"))
    save(TSHB_S1,file="TSHB_cc_ub.Rdata")
#}else{
#    load("TSHB_cc.Rdata")
#}

TSHB_S1_dat<-data.frame("Ca"=TSHB_S1$summary[grepl("^Ca",rownames(TSHB_S1$summary)),1],
                    "logCaw"=TSHB_S1$summary[grepl("^logCaw",rownames(TSHB_S1$summary)),1],
                    "logDaw"=TSHB_S1$summary[grepl("^logDaw",rownames(TSHB_S1$summary)),1]
                    )
TSHB_S1_dat$id <- as.numeric(unlist(lapply(rownames(TSHB_S1_dat),function(x) strsplit(strsplit(x,"\\[")[[1]][2],"\\]")[[1]])))
TSHB_S1_dat    <- TSHB_S1_dat[order(TSHB_S1_dat$id),]
TSHB_StageIX   <- cbind(TSHB_S1_dat,datX)

# Stage II -  edit to include any additional Stage II covariates (e.g., confounder adjustments)
TS_HB_Ca     <-lme(Ca ~ X,     random=~1|id, data = TSHB_StageIX, na.action = na.omit)
TS_HB_logCaw <-lme(logCaw ~ X, random=~1|id, data = TSHB_StageIX, na.action = na.omit)
TS_HB_logDaw <-lme(logDaw ~ X, random=~1|id, data = TSHB_StageIX, na.action = na.omit)

```

<br>

**Convergence diagnostic**

We used Rhat (See Gelman and Rubin (1992), Brooks and Gelman (1998)]) to assess the convergence of the MCMC simulation mdoel.

Here we printed out the estimations (95% CL) and their Rhats (converge if <1.1 )

```{r,echo=FALSE}
kable(TSHB_S1$summary[c("beta0_Ca","beta0_logCaw","beta0_logDaw","sdCa","sdlogCaw","sdlogDaw","corlogCawCa","corlogCawlogDaw","corlogDawCa",
                        "sigma_c"),c("2.5%","mean","97.5%","Rhat")])

```

<br>

#### 2.6  U_HB: Unified Hierarchical Bayesian method

Here we also loaded the already fitted U_HB results due to the large amount of time for simulation.

```{r uhb, results='hide', cache=TRUE}
source("U_HB.R")

#if(!file.exists("UHB_cc.Rdata")){
    set.seed(2020)
    UHB_sim<-UHB_iter_UB(beta0_prior=c(2,4,3),
             betaC_prior =c(0.1,0.1,0.1),
             rhat=1.1,addon.iter=100,Max_update=1,n.final=100,
             N.iterT=1200,N.burnin=1000,N.thinM=1,N.chain=3, 
             flow=flow,dat=dat,X=datX[,2],
             tracing=c("beta0_Ca","beta0_logCaw","beta0_logDaw",
                       "beta1_Ca","beta1_logCaw","beta1_logDaw",
                       "sdCa","sdlogCaw","sdlogDaw",
                       "corlogCawCa","corlogCawlogDaw","corlogDawCa",
                       "sigma_c"))
    save(UHB_sim,file="UHB_cc_ub.Rdata")
#}else{
#    load("UHB_cc.Rdata")
#}

```

<br>

**Convergence diagnostic** 

We print out the estimation (95% CL) and Rhat (converge if <1.1 )
```{r,echo=FALSE}
kable(UHB_sim$summary[c("beta0_Ca","beta0_logCaw","beta0_logDaw",
                  "beta1_Ca","beta1_logCaw","beta1_logDaw",
                  "sdCa","sdlogCaw","sdlogDaw",
                  "corlogCawCa","corlogCawlogDaw","corlogDawCa",
                  "sigma_c"),c("2.5%","mean","97.5%","Rhat")])

```

<br>

## 3. Create plot comparing estimated NO parameter associations across 6 methods

* Y axis: 6 methods
* X axis: coefficient effect size: The values used in simulation were all equaled to 0.1 for CANO, logCawNO and logDawNO. Which means for 1 unit increase in the covariate X, the corresponding NO paramters CANO, logCawNO and logDawNO increase 0.1 unit. The geometric interpretation for CawNO  was that it was (exp(`r truebeta[2]`)-1) times higher for 1 unit increase in the covariate, so was for DawNO
* Refernce lines: Black lines indicate the values used in data simulation. Gray lines indicate the values obtained by regression on the simulated NO parameters and Xs.

```{r storeresults,echo=FALSE}

# store results from all methods in allResults dataset for easier plotting
sixMethods <- c("TS_NLS","TS_HMA","TS_NLME","U_NLME","TS_HB","U_HB")
nModels <- length(sixMethods)
allResults <- data.frame(method = rep(sixMethods,each=3),
                         NOparam = rep(c("Ca","logCaw","logDaw"),nModels),
                         est= rep(NA,3*nModels),
                         lb = rep(NA,3*nModels),
                         ub = rep(NA,3*nModels)
                         )

# extract TS_NLS results
allResults[allResults$method=="TS_NLS" & allResults$NOparam=="Ca",c("lb","est","ub")]     <- intervals(TS_NLS_Ca,which="fixed")[[1]]["X",]
allResults[allResults$method=="TS_NLS" & allResults$NOparam=="logCaw",c("lb","est","ub")] <- intervals(TS_NLS_logCaw,which="fixed")[[1]]["X",]
allResults[allResults$method=="TS_NLS" & allResults$NOparam=="logDaw",c("lb","est","ub")] <- intervals(TS_NLS_logDaw,which="fixed")[[1]]["X",]
# extract TS_HMA results
allResults[allResults$method=="TS_HMA" & allResults$NOparam=="Ca",c("lb","est","ub")]     <- intervals(TS_HMA_Ca,which="fixed")[[1]]["X",]
allResults[allResults$method=="TS_HMA" & allResults$NOparam=="logCaw",c("lb","est","ub")] <- intervals(TS_HMA_logCaw,which="fixed")[[1]]["X",]
allResults[allResults$method=="TS_HMA" & allResults$NOparam=="logDaw",c("lb","est","ub")] <- intervals(TS_HMA_logDaw,which="fixed")[[1]]["X",]
# extract TS_NLME results
allResults[allResults$method=="TS_NLME" & allResults$NOparam=="Ca",c("lb","est","ub")]     <- intervals(TS_NLME_Ca,which="fixed")[[1]]["X",]
allResults[allResults$method=="TS_NLME" & allResults$NOparam=="logCaw",c("lb","est","ub")] <- intervals(TS_NLME_logCaw,which="fixed")[[1]]["X",]
allResults[allResults$method=="TS_NLME" & allResults$NOparam=="logDaw",c("lb","est","ub")] <- intervals(TS_NLME_logDaw,which="fixed")[[1]]["X",]
# extract U_NLME results
allResults[allResults$method=="U_NLME" & allResults$NOparam=="Ca",c("lb","est","ub")]     <- intervals(U_NLMEout,which = "fixed")[[1]]["CaNO.X",]
allResults[allResults$method=="U_NLME" & allResults$NOparam=="logCaw",c("lb","est","ub")] <- intervals(U_NLMEout,which = "fixed")[[1]]["logCawNO.X",]
allResults[allResults$method=="U_NLME" & allResults$NOparam=="logDaw",c("lb","est","ub")] <- intervals(U_NLMEout,which = "fixed")[[1]]["logDawNO.X",]
# extract TS_HB results
allResults[allResults$method=="TS_HB" & allResults$NOparam=="Ca",c("lb","est","ub")]     <- intervals(TS_HB_Ca,which="fixed")[[1]]["X",]
allResults[allResults$method=="TS_HB" & allResults$NOparam=="logCaw",c("lb","est","ub")] <- intervals(TS_HB_logCaw,which="fixed")[[1]]["X",]
allResults[allResults$method=="TS_HB" & allResults$NOparam=="logDaw",c("lb","est","ub")] <- intervals(TS_HB_logDaw,which="fixed")[[1]]["X",]
# extract U_HB results
allResults[allResults$method=="U_HB" & allResults$NOparam=="Ca",c("lb","est","ub")]     <- UHB_sim$summary[c("beta1_Ca"),c("2.5%","mean","97.5%")]
allResults[allResults$method=="U_HB" & allResults$NOparam=="logCaw",c("lb","est","ub")] <- UHB_sim$summary[c("beta1_logCaw"),c("2.5%","mean","97.5%")]
allResults[allResults$method=="U_HB" & allResults$NOparam=="logDaw",c("lb","est","ub")] <- UHB_sim$summary[c("beta1_logDaw"),c("2.5%","mean","97.5%")]

```


```{r plotresults, echo=FALSE,fig.width=10,fig.height=8}
par(mfrow=c(3,1),mar=c(4,6,3,1), mgp=c(2,.7,0), tck=-.01)
################################
## Association of CANO with X ##
################################
# global ylims
mymin <- min(subset(allResults,NOparam=="Ca")$lb,na.rm=TRUE)
mymax <- max(subset(allResults,NOparam=="Ca")$ub,na.rm=TRUE)
# plot estimates
plot(subset(allResults,NOparam=="Ca")$est, nModels:1,
     pch=16, col="blue", cex.lab=1.3, cex.axis=1.3, cex=1.7,
     yaxt="n", ylab="", ylim=c(.5,nModels+.5),
     xlim=range(c(0,mymin,mymax)),
     xlab="Difference in CANO, ppb, per 1 unit difference in X"
     )
# add line at true value
abline(v=truebeta[1],col="black")#
# add line at the estmated value
abline(v=estParam[2,1],col="gray")
# add 95% CI
segments(subset(allResults,NOparam=="Ca")$lb,nModels:1,
         subset(allResults,NOparam=="Ca")$ub,nModels:1,lwd=2,col="blue")
# axis labels
par(las=2)
axis(2, at=nModels:1, tick=FALSE,
     labels=sixMethods,cex.axis=1.3)
par(las=0)

#################################
## Association of CawNO with X ## requires exponentiation to get on % difference scale
#################################
# global ylims
mymin <- min(subset(allResults,NOparam=="logCaw")$lb,na.rm=TRUE)
mymax <- max(subset(allResults,NOparam=="logCaw")$ub,na.rm=TRUE)
# plot estimates
plot((exp(subset(allResults,NOparam=="logCaw")$est)-1)*100, nModels:1,
     pch=16, col="blue", cex.lab=1.3, cex.axis=1.3, cex=1.7,
     yaxt="n", ylab="", ylim=c(.5,nModels+.5),
     xlim=(exp(range(c(0,mymin,mymax)))-1)*100,
     xlab="% Difference in CawNO per 1 unit difference in X"
     )
# add line at true value
abline(v=(exp(truebeta[2])-1)*100,col="black") # 
abline(v=(exp(estParam[2,2])-1)*100,col="gray")
# add 95% CI
segments((exp(subset(allResults,NOparam=="logCaw")$lb)-1)*100,
         nModels:1,
         (exp(subset(allResults,NOparam=="logCaw")$ub)-1)*100,
         nModels:1,
         lwd=2,col="blue")
# axis labels
par(las=2)
axis(2, at=nModels:1, tick=FALSE,
     labels=sixMethods,cex.axis=1.3)
par(las=0)

#################################
## Association of DawNO with X ## requires exponentiation to get on % difference scale
#################################
# global ylims
mymin <- min(subset(allResults,NOparam=="logDaw")$lb,na.rm=TRUE)
mymax <- max(subset(allResults,NOparam=="logDaw")$ub,na.rm=TRUE)
# plot estimates
plot((exp(subset(allResults,NOparam=="logDaw")$est)-1)*100, nModels:1,
     pch=16, col="blue", cex.lab=1.3, cex.axis=1.3, cex=1.7,
     yaxt="n", ylab="", ylim=c(.5,nModels+.5),
     xlim=(exp(range(c(0,mymin,mymax)))-1)*100,
     xlab="% Difference in DawNO per 1 unit difference in X"
     )
# add line at true value
abline(v=(exp(truebeta[3])-1)*100,col="black") #
abline(v=(exp(estParam[2,3])-1)*100,col="gray")
# add 95% CI
segments((exp(subset(allResults,NOparam=="logDaw")$lb)-1)*100,
         nModels:1,
         (exp(subset(allResults,NOparam=="logDaw")$ub)-1)*100,
         nModels:1,
         lwd=2,col="blue")
# axis labels
par(las=2)
axis(2, at=nModels:1, tick=FALSE,
     labels=sixMethods,cex.axis=1.3)
par(las=0)


```
